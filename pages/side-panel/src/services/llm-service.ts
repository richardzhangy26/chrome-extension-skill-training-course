/**
 * LLM æœåŠ¡ - è°ƒç”¨è±†åŒ…æ¨¡å‹ç”Ÿæˆå›ç­”
 * å‚è€ƒ Python: auto_script_train.py ä¸­çš„ _call_doubao_post æ–¹æ³•
 */

import { DEFAULT_SYSTEM_PROMPT, DEFAULT_PROFILE_ID, llmConfigStorage } from '@extension/storage';
import type { LLMConfig } from '@extension/storage';

interface ChatMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

interface LLMResponse {
  success: boolean;
  content?: string;
  error?: string;
}

const resolveSystemPrompt = (config: LLMConfig) => {
  if (config.systemPromptMode === 'custom' && config.systemPrompt.trim()) {
    return config.systemPrompt.trim();
  }

  return DEFAULT_SYSTEM_PROMPT;
};

const resolveStudentProfile = (config: LLMConfig) => {
  const profiles = config.studentProfiles;
  const selected = profiles.find(profile => profile.id === config.studentProfileId);

  return (
    selected ?? profiles[0] ?? { id: DEFAULT_PROFILE_ID, label: 'å­¦ç”Ÿ', description: '', style: '', fallbackHint: '' }
  );
};

const buildUserMessage = (aiQuestion: string, profile: { label: string; description: string; style: string }) => {
  const sections = [
    '## è§’è‰²è®¾å®š',
    `å­¦ç”Ÿæ¡£ä½: ${profile.label}`,
    `è§’è‰²ç‰¹å¾: ${profile.description}`,
    `è¡¨è¾¾é£æ ¼: ${profile.style}`,
    '',
  ];

  sections.push('## å½“å‰é—®é¢˜', aiQuestion, '');

  return sections.join('\n');
};

/**
 * è°ƒç”¨è±†åŒ…æ¨¡å‹ç”Ÿæˆå­¦ç”Ÿå›ç­”
 */
const generateStudentAnswer = async (
  aiQuestion: string,
  conversationHistory: Array<{ ai: string; student: string }> = [],
): Promise<LLMResponse> => {
  // è·å–é…ç½®
  const config = await llmConfigStorage.get();

  if (!config.apiKey) {
    return { success: false, error: 'è¯·å…ˆé…ç½® LLM API Key' };
  }

  try {
    const systemPrompt = resolveSystemPrompt(config);
    const profile = resolveStudentProfile(config);
    const userMessage = buildUserMessage(aiQuestion, profile);

    const historyMessages: ChatMessage[] = [];
    for (const turn of conversationHistory.slice(-5)) {
      historyMessages.push({ role: 'assistant', content: turn.ai });
      historyMessages.push({ role: 'user', content: turn.student });
    }

    const messages: ChatMessage[] = [
      { role: 'system', content: systemPrompt },
      ...historyMessages,
      { role: 'user', content: userMessage },
    ];

    // è°ƒç”¨ API
    const response = await fetch(config.apiUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'api-key': config.apiKey,
        'service-code': config.serviceCode,
      },
      body: JSON.stringify({
        model: config.model,
        messages,
        temperature: 0.7,
        max_tokens: 200,
        top_p: 0.9,
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('LLM API Error:', response.status, errorText);
      return { success: false, error: `API è¯·æ±‚å¤±è´¥: ${response.status}` };
    }

    const data = await response.json();
    const content = data?.choices?.[0]?.message?.content?.trim();

    if (!content) {
      return { success: false, error: 'æ¨¡å‹æœªè¿”å›æœ‰æ•ˆå†…å®¹' };
    }

    console.log('ğŸ¤– LLM ç”Ÿæˆå›ç­”:', content);
    return { success: true, content };
  } catch (error) {
    console.error('LLM Service Error:', error);
    return { success: false, error: `è°ƒç”¨å¤±è´¥: ${(error as Error).message}` };
  }
};

/**
 * æµ‹è¯• LLM é…ç½®æ˜¯å¦æœ‰æ•ˆ
 */
const testLLMConfig = async (config: LLMConfig): Promise<LLMResponse> => {
  try {
    const response = await fetch(config.apiUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'api-key': config.apiKey,
        'service-code': config.serviceCode,
      },
      body: JSON.stringify({
        model: config.model,
        messages: [{ role: 'user', content: 'ä½ å¥½' }],
        max_tokens: 10,
      }),
    });

    if (!response.ok) {
      return { success: false, error: `API è¿æ¥å¤±è´¥: ${response.status}` };
    }

    return { success: true, content: 'é…ç½®æœ‰æ•ˆ' };
  } catch (error) {
    return { success: false, error: `è¿æ¥å¤±è´¥: ${(error as Error).message}` };
  }
};

export { generateStudentAnswer, testLLMConfig };
